---
title: "hw_5"
author: "Yasasvi"
date: "2024-03-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(cluster)
library(readr)
library(factoextra)
library(NbClust)

iris_data <- iris

# Hierarchical Clustering
# Standardize the data
scaled_iris <- scale(iris_data[, -5])

# Compute distance matrix
dist_iris <- dist(scaled_iris)

# hierarchical clustering using Ward's method
hierarchical_result <- hclust(dist_iris, method = "ward.D2")

# Decide the optimal number of clusters
# Use NbClust to determine the optimal number of clusters based on different criteria
nbclust_result <- NbClust(scaled_iris, distance = "euclidean", min.nc = 2, max.nc = 10, method = "complete", index = "all")

# Visualize NbClust results
print(nbclust_result)

# From NbClust, select the optimal number of clusters based on the criteria you prefer
optimal_clusters <- 3  # For example, let's choose 3 clusters

# Cut the dendrogram to get cluster membership
hierarchical_clusters <- cutree(hierarchical_result, k = optimal_clusters)

# Show membership for each cluster
table(hierarchical_clusters)

# Visualize dendrogram with optimal number of clusters
plot(hierarchical_result, main = paste("Dendrogram with", optimal_clusters, "Clusters"))

# Non-hierarchical Clustering (K-means)
# Determine the optimal number of clusters using NbClust
nbclust_result <- NbClust(scaled_iris, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index = "all")

#Explanation: NbClust provides 30 indices for determining the number of clusters, including the silhouette index, the Duda-Hart index, and the Calinski-Harabasz index, among others.

#We can choose the optimal number of clusters based on the indices that show the highest values or significant changes.

# Visualize NbClust results
print(nbclust_result)

# From NbClust, select the optimal number of clusters based on the criteria you prefer
optimal_clusters_kmeans <- 3

# Perform K-means clustering
kmeans_result <- kmeans(scaled_iris, centers = optimal_clusters_kmeans, nstart = 25)

# Show membership for each cluster
table(kmeans_result$cluster)

# Visualize K-means clustering using the first two principal components
# Perform PCA
pca_result <- prcomp(scaled_iris, scale. = TRUE)

# Extract PC scores
pc_scores <- as.data.frame(pca_result$x[, 1:2])

# Add cluster membership to PC scores
pc_scores_with_clusters_kmeans <- cbind(pc_scores, Cluster = kmeans_result$cluster)

# Scatter plot of PC scores with cluster membership for K-means clustering
fviz_cluster(kmeans_result, data = pc_scores, geom = "point", stand = FALSE, main = "K-means Clustering with PC1 vs PC2")
```